# TRUSTED AI SOC LITE

Prototype local Security Operations Center (SOC) that combines automated Nmap scans, explainable analytics, Wazuh SIEM integration and a console dashboard. The project now runs fully offline using only the Python standard library.

## ğŸ“¦ Project Structure

```
trusted_ai_soc_lite/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ settings.yaml
â”œâ”€â”€ scanner/
â”‚   â”œâ”€â”€ nmap_scan.py
â”‚   â””â”€â”€ parse_results.py
â”œâ”€â”€ ai_engine/
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ detect_anomalies.py
â”‚   â””â”€â”€ xai_explain.py
â”œâ”€â”€ response/
â”‚   â”œâ”€â”€ block_ip.py
â”‚   â””â”€â”€ notify.py
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ audit.py
â”‚   â”œâ”€â”€ audit.json              # generated
â”‚   â”œâ”€â”€ wazuh_events.ndjson     # generated
â”‚   â””â”€â”€ scans/                  # generated
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_pipeline.py
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ wazuh/
â”‚       â”œâ”€â”€ ossec.local.conf
â”‚       â”œâ”€â”€ decoders/
â”‚       â”‚   â””â”€â”€ trusted-ai-soc_decoders.xml
â”‚       â””â”€â”€ rules/
â”‚           â””â”€â”€ trusted-ai-soc_rules.xml
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

## ğŸš€ Quickstart (Debian / Linux)

1. **Install prerequisites**

   ```bash
   sudo apt update && sudo apt install -y python3 python3-venv python3-pip nmap make docker.io docker-compose
   ```

2. **Clone and enter the repository**

   ```bash
   git clone <repo-url> trusted_ai_soc_lite
   cd trusted_ai_soc_lite
   ```

3. **Create the Python environment**

   ```bash
   make install
   ```

   The core pipeline has no third-party Python dependencies, so the command simply creates a virtual environment. If you keep a custom `requirements.txt`, the Makefile will install the listed wheels when a local cache is provided via `WHEEL_DIR=...`.

4. **Run a scan and score it**

   ```bash
   make scan        # collects Nmap output (simulated if nmap is missing)
   make parse       # converts the latest scan to CSV
   make train       # trains the statistical baseline
   make detect      # scores the parsed results and writes detections JSON
   make xai         # generates human-readable explanations
   # or run everything in one shot:
   make pipeline
   ```

5. **View the latest results**

   ```bash
   make dashboard
   ```

   The dashboard prints a textual summary of detections, explanations and recent audit events to the terminal.

## ğŸ”„ Automation Workflow

1. `scanner/nmap_scan.py` collects raw vulnerability data (XML or simulated JSON when Nmap is unavailable).
2. `scanner/parse_results.py` converts scans into structured dictionaries and optional CSV output.
3. `ai_engine/train_model.py` builds a statistical baseline (port/service frequency model) stored as JSON.
4. `ai_engine/detect_anomalies.py` scores new scans against the baseline, produces severity labels and writes detections JSON while auditing anomalies.
5. `ai_engine/xai_explain.py` reformats detection explanations for analysts and logs them.
6. `response/block_ip.py` and `response/notify.py` execute automated defense and alerting.
7. `dashboard/app.py` renders a console dashboard for quick situational awareness.

All actions are recorded through `logs/audit.py` in both JSON and NDJSON formats to feed Wazuh.

## ğŸ“‘ Wazuh Integration

- Mount `integration/wazuh` into `/var/ossec/etc/shared/trusted-ai-soc` on the manager.
- Configure `ossec.local.conf` to tail `/var/trusted-ai-soc/logs/wazuh_events.ndjson`.
- Decoders and rules are included to tag anomaly and response events from the SOC.

## âš™ï¸ Configuration

- `config/settings.yaml` holds all tunables: scan targets, anomaly thresholds, notification backends and audit file paths.
- `.env` exposes runtime variables for containers and dashboard credentials.

## ğŸ§ª Testing the Pipeline

You can simulate data without Nmap by running:

```bash
python3 scanner/nmap_scan.py --config config/settings.yaml
python3 scanner/parse_results.py logs/scans/$(ls -t logs/scans | head -n1) --output logs/parsed.csv
python3 ai_engine/train_model.py logs/parsed.csv --config config/settings.yaml
python3 ai_engine/detect_anomalies.py logs/parsed.csv --config config/settings.yaml
python3 ai_engine/xai_explain.py logs/parsed.csv logs/explanations/$(ls -t logs/explanations/detections_*.json | head -n1) --config config/settings.yaml
```

The fallback simulator will create sample detections which appear in the dashboard.

## ğŸ” Security Considerations

- Run all Docker containers on an isolated network segment.
- Replace default credentials and SMTP settings before production use.
- Review generated explanations to validate anomaly decisions.

## ğŸ“š Documentation & Deliverables

- **Scripts** for scanning, analytics, response, dashboard and audit logging.
- **Docker assets** for reproducible deployment with Wazuh stack.
- **Audit trail** persisted in JSON & NDJSON for compliance.
- **Dashboard** providing textual metrics, alerts and audit history.

## ğŸ§­ Next Steps / Extensions

- Integrate OpenVAS feeds for deeper vulnerability coverage.
- Connect to OTX or MISP for threat intelligence enrichment.
- Automate PDF reporting with weekly summaries.
- Add honeypot or deception telemetry to the pipeline.
